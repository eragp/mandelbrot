\section{Ergebnisse / Evaluation}
\begin{itemize}
	\item Skalierbarkeitsgraph
	\item Wie gut ist SIMD / OpenMP / MPI / Mischformen?
	\item Frontend Overhead messen
\end{itemize}


%%%%%%%
% http://www.caps.in.tum.de/himmuc/
% Datenerhebenung (+ auf himmuc!) -> Max
% Skalierungs bzgl anzahl an nodes
% Vergleich OpenMP und mehrere MPI pro Node -> Tobi
% Overhead durch Balancer -> Florian
% Overhead durch MPI / Websocket / DrawTiles (konstant)
% Vergleich SIMD / Rohcode -> Niels

% Nutzbarkeit/ HCI -> Max
% vergleich x86 -> Max
\subsection{Performanzerhöhung alternative Parallelisierungsmechanismen}

\subsubsection{SIMD}

% refactor:
% three bar graphs - average computation time for worst 25%, average 50% and best 50%
% one figure showing where SIMD achieves best increase in performance (see notebook)

SIMD unterstützt in den Präzisionen 32 und 64 bit Parallelisierung von einer Rechenoperationen auf
4 beziehungsweise 2 unterschiedlichen Werten. Der Effekt beläuft sich dabei, wie in \autoref{fig:SIMD-speedup} zu sehen,
auf eine durchschnittliche Beschleunigung um den Faktor 1,9 und 1,2.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{img/Evaluation/impl_test}
	\caption{Vergleich der Performanzen der Implementierungen mit und ohne SIMD}
	\label{fig:SIMD-speedup}
\end{figure}

Dass die Performanzerhöhung nicht genau 4 oder 2 ist, lässt sich mit dem Erhöhten Aufwand der Verwendung
der SIMD Instruktionen erklären.
Da hierzu die Werte aus den normalen Registern in spezielle SIMD-Register und zurück
kopiert werden müssen, entsteht eine gewisse Verzögerung durch zusätzliche Transportoperationen.
Die tatsächliche Rechenzeit für eine Vektorisierung von \(n\) Punkten sollte also \autoref{equ:simd-time} entsprechen.

\begin{equation}\label{equ:simd-time}
    t_{SIMD} \approx \frac{t_{normal}}{n}+ const
\end{equation}

Je größer die benötigte Zahl an Operationen, desto weniger fällt dieser konstante Zusatzaufwand ins Gewicht.
Dies kann zum Beispiel in \autoref{fig:SIMD-speedup-vs-comptime} beobachtet werden.

Zudem werden für eine Menge an Punkten stets die Zahl an Iterationen durchgeführt,
die das Maximum aller Iterationszahlen der Punkte ist.
Bei Iterationszahlen \(i_k\) des Punktvektors \(p\) ist daher
anstatt einer Rechenzeit von \(\sum_{k \in p} \frac{i_k }{ | p | }\) eine Rechenzeit von
\(\sum_{k \in p} \frac{max(i_k)_{k \in p }}{|p|} = max(i_k)_{k \in p }\) pro Punktvektor zu erwarten.
Damit wird die Beschleunigung durch SIMD kleiner, je inhomogener die Iterationszahlen sind.
Dass die Iterationszahlen im Allgemeinen am Rand der Mandelbrotmenge inhomogener sind,
wo auch die Gesamtrechenzeit geringer ist, sollte bei der Betrachtung von \autoref{fig:SIMD-speedup-vs-comptime} berücksichtigt werden.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{img/Evaluation/speedupvscomptime}
    \caption{Beschleunigungsfaktor durch SIMD in Abhängigkeit von der durchschnittlichen Rechenzeit}
  	\label{fig:SIMD-speedup-vs-comptime}
\end{figure}

\paragraph{Notiz, entdeckt durch das In-Betracht-Ziehen der Leerregionen}

Probleme bei der Verwendung des Rekursiven Lastbalanierers:
Da es stets im Diskreten eine Minimalgröße für die aufgeteilten Regionen gibt,
kann es sein, dass eine Region für die eine hohe Last vorhergesagt wird viele Worker reserviert -
diese jedoch nicht vollständig ausreizen kann, da die Maximalaufteilung schon erreicht wurde.
Durch die dadurch entstehenden Leerregionen von nicht verwendbaren Workern
kann eine suboptimale Aufteilung enstehen, schlechter noch als die des naiven rekursiven Balancierers.

Dies kann abgeschwächt werden, indem eine Region stets nur soviel Workerressourcen erhält,
wie sie maximal auslasten könnte (Fläche/Fläche minimaler Aufteilung)
